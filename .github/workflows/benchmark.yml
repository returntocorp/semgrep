on:
  push:
    # Sequence of patterns matched against refs/tags
    branches:
      - "develop"
      - "master"
    tags:
      - "v*" # Push events to matching v*, i.e. v1.0, v20.15.10
  pull_request:

      # This string is matched in `latest-artifact-for-branch.py`
name: Incorporate Benchmark Data
jobs:
  benchmark-persist:
    runs-on: ubuntu-latest
    container: returntocorp/sgrep-build:2.8
    steps:
      - name: Adjust permissions
        run: sudo chmod -R 777 . /github
      - name: Checkout
        uses: actions/checkout@v2
      - name: Install submodules
        run: git submodule update --init --recursive
      - name: Retrieve the latest performance run
        run: ./install-scripts/latest-artifact-for-branch.py
        env:
          AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BENCHMARK: "y"
          BRANCH: "develop"
          OUT_DIR: "semgrep/benchmarks"
      - name: Install pfff
        run: eval $(opam  env --root /home/opam/.opam --set-root) && opam install -y ./pfff
      - name: Install semgrep-core
        run: eval $(opam  env --root /home/opam/.opam --set-root) && cd semgrep-core && opam install --deps-only -y . && make all && make install
      - name: Install bootstrapping packages for Python
        run: |
          export PATH=/github/home/.local/bin:$PATH
          pip3 install pipenv==2018.11.26 wheel==0.34.2
      - name: Install semgrep
        run: |
          cd semgrep
          export PATH=/github/home/.local/bin:$PATH
          pipenv install --dev
      - name: check semgrep
        run: |
          cd semgrep
          export PATH=/github/home/.local/bin:$PATH
          pipenv run semgrep --version
      - uses: actions/cache@v2
        with:
          path: ~/.cache/semgrep-cache
          key: semgrep-repo-cache-bench
      - name: run benchmarks
        run: |
          cd semgrep
          mkdir -p ~/.cache/semgrep-cache
          # TODO: figure out what checks we want to run on PRs
          eval $(opam  env --root /home/opam/.opam --set-root)
          export PATH=/github/home/.local/bin:$PATH
          pipenv run pytest -k test_ci_perf tests/ --benchmark-min-rounds 1 --benchmark-only --benchmark-autosave --benchmark-storage benchmarks
        env:
          GITHUB_REPO_CACHE: ~/.cache/semgrep-cache
      - name: Compare to previous benchmark result
        run: |
          cd semgrep
          eval $(opam  env --root /home/opam/.opam --set-root)
          export PATH=/github/home/.local/bin:$PATH
          pipenv run py.test-benchmark compare benchmarks/Linux-*/* --group-by name --sort name
        # compare to previous runs, even if we had a timeout or a test failure
        if: ${{ always() }}
      - name: Upload benchmark results
        uses: actions/upload-artifact@v1
        with:
          name: benchmarks
          path: semgrep/benchmarks
